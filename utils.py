# Client software for synchronising sequence definition and isolate databases
# with a remote BIGSdb installation via the API
# Written by Keith Jolley
# Copyright (c) 2025-2026, University of Oxford
# E-mail: keith.jolley@biology.ox.ac.uk
#
# BIGSdb_sync is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# BIGSdb_sync is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

import argparse
import re
import os
import stat
from pathlib import Path
import logging
import sys
import socket
from urllib.parse import urlparse
import time
import sys

import config
from errors import ConfigError


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--add_lincode_fields",
        action="store_true",
        help="Add an LIN code fields defined for a LIN code scheme. These should have been added "
        "when the LIN code scheme was first defined, but you can use this if they have been added later.",
    )
    parser.add_argument(
        "--add_lincode_schemes",
        action="store_true",
        help="Add LIN code scheme to existing scheme. This would have been added automatically "
        "when the scheme was set up if the LIN code scheme existed. This should be used when LIN "
        "codes are added to a scheme at a later date.",
    )
    parser.add_argument(
        "--add_lincodes",
        action="store_true",
        help="Add LIN codes for defined profiles that are currently missing them. "
        "This is only necessary if LIN codes have not been added when first defining profiles as "
        "these should have been added at the same time as the profile if the LIN code scheme was "
        "defined at the time.",
    )
    parser.add_argument(
        "--add_loci",
        action="store_true",
        help="Set up new loci if they do not exist in local database.",
    ),
    parser.add_argument(
        "--add_missing_profile_alleles",
        action="store_true",
        help="Add alleles that have not been defined when adding profiles. "
        "Note that you should still run --add_seqs regularly as this is much more efficient "
        "as it will download multiple alleles in a batch rather than individually.",
    )
    parser.add_argument(
        "--add_profiles", action="store_true", help="Add new profiles."
    ),
    parser.add_argument("--add_schemes", action="store_true", help="Add new schemes."),
    parser.add_argument(
        "--add_seqs", action="store_true", help="Add new allele/variant sequences."
    )
    parser.add_argument(
        "--api_db_url",
        required=True,
        help="URL for the top-level database API call, e.g. https://rest.pubmlst.org/db/pubmlst_neisseria_seqdef.",
    )
    parser.add_argument(
        "--base_web_url",
        required=False,
        help="URL to BIGSdb script on target web site.",
    ),
    parser.add_argument(
        "--check_lincodes",
        action="store_true",
        help="Warn of changes to LIN codes of existing profiles.",
    )
    parser.add_argument(
        "--check_profiles",
        action="store_true",
        help="Warn of changes to existing profiles.",
    )
    parser.add_argument(
        "--check_seqs",
        action="store_true",
        help="Warn of changes to attributes of existing sequences.",
    )
    parser.add_argument(
        "--cron",
        action="store_true",
        help="Script is being run as a CRON job or non-interactively.",
    )
    parser.add_argument("--db", required=True, help="Local database config name.")
    parser.add_argument(
        "--delay",
        required=False,
        default=0,
        type=int_in_range(0, 60),
        help="Add a delay (in seconds) between API calls (default 0).",
    )
    parser.add_argument(
        "--key_name",
        required=True,
        help="Name of API key - use a different name for each site.",
    )
    parser.add_argument("--loci", required=False, help="Comma-separated list of loci.")
    parser.add_argument(
        "--loci_with_no_alleles_only",
        action="store_true",
        help="Only add alleles for loci that have no local alleles defined (useful after adding new loci)",
    )
    parser.add_argument(
        "--log_file",
        required=False,
        default="/var/log/bigsdb_sync.log",
        help="Path to log file if run with --cron option.",
    )
    parser.add_argument(
        "--log_level",
        required=False,
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="Log level.",
    )
    parser.add_argument(
        "--page_size",
        required=False,
        type=int_in_range(10, 1000),
        help="Size of page to request from API. Default is to leave it up to the API. ",
    )
    parser.add_argument(
        "--reldate",
        required=False,
        type=int,
        help="Only add/update records modified in the last X days.",
    )
    parser.add_argument(
        "--schemes", required=False, help="Comma-separated list of scheme ids."
    )
    parser.add_argument(
        "--token_dir",
        required=False,
        default=str(config.DEFAULT_TOKEN_DIR),
        help="Directory into which keys and tokens will be saved.",
    )
    parser.add_argument(
        "--verbose", action="store_true", help="Provide more detailed output."
    ),
    parser.add_argument(
        "--update_lincodes",
        action="store_true",
        help="Update LIN codes if they have changed.",
    )
    parser.add_argument(
        "--update_profiles",
        action="store_true",
        help="Update profiles or their attributes if they have changed.",
    )
    parser.add_argument(
        "--update_seqs",
        action="store_true",
        help="Update sequence attributes if they have changed.",
    )
    return parser.parse_args()


def init_logger():
    logger = logging.getLogger(__name__)
    if config.args.log_level is None:
        if config.args.cron:
            config.args.log_level = "ERROR"
        else:
            config.args.log_level = "INFO"
    level = logging.getLevelName(config.args.log_level)
    logger.setLevel(level)
    logger.propagate = False
    formats = {
        "cron_debug": "%(asctime)s - %(levelname)s: - %(module)s:%(lineno)d - %(message)s",
        "cron": "%(asctime)s - %(levelname)s: - %(message)s",
        "interactive_debug": "%(levelname)s: - %(module)s:%(lineno)d - %(message)s",
        "interactive": "%(levelname)s: %(message)s",
    }

    if config.args.cron:
        log_path = Path(config.args.log_file)
        if log_path.exists():
            if not os.access(log_path, os.W_OK):
                sys.stderr.write(
                    f"CRITICAL: Log file {config.args.log_file} exists but is not writable.\n"
                )
                sys.exit(1)
        else:
            try:
                log_path.touch(mode=0o644, exist_ok=False)
            except Exception as e:
                sys.stderr.write(f"CRITICAL: Failed to create log file: {e}.\n")
                sys.exit(1)
        f_handler = logging.FileHandler(config.args.log_file)
        f_handler.setLevel(level)
        fmt = (
            formats.get("cron_debug")
            if config.args.log_level == "DEBUG"
            else formats.get("cron")
        )
        f_format = logging.Formatter(fmt)
        f_handler.setFormatter(f_format)
        logger.addHandler(f_handler)
    else:
        c_handler = logging.StreamHandler()
        c_handler.setLevel(level)
        fmt = (
            formats.get("interactive_debug")
            if config.args.log_level == "DEBUG"
            else formats.get("interactive")
        )
        c_format = logging.Formatter(fmt)
        c_handler.setFormatter(c_format)
        logger.addHandler(c_handler)
    return logger


def check_required_args():
    if not re.search(r"^https?://.*/db/[A-Za-z0-9_-]+$", config.args.api_db_url):
        raise ConfigError(
            "--api_db_url should be a valid URL (starting with http(s):// and\n"
            "ending with /db/xxx where xxx is a database configuration)."
        )


def check_token_dir(directory):
    if os.path.isdir(directory):
        if os.access(directory, os.W_OK):
            return
        else:
            raise ConfigError(
                f"The token directory '{directory}' exists but is not writable."
            )
    else:
        try:
            os.makedirs(directory)
            os.chmod(directory, stat.S_IRWXU)  # Set permissions to 0700
        except OSError as e:
            raise ConfigError(f"Failed to create token directory '{directory}': {e}")


def extract_locus_names_from_urls(urls):
    return [url.rstrip("/").split("/")[-1] for url in urls]


def extract_last_value_from_url(url):
    return url.rstrip("/").split("/")[-1]


def get_selected_scheme_list():
    if config.args.schemes:
        try:
            scheme_list = sorted(
                {int(scheme_id.strip()) for scheme_id in config.args.schemes.split(",")}
            )
        except ValueError as e:
            raise ConfigError(
                f"Invalid non-integer value found in --schemes argument. {e}"
            )
        return scheme_list


def get_selected_locus_list():
    if config.args.loci:
        locus_list = sorted({locus.strip() for locus in config.args.loci.split(",")})
        return locus_list


def check_api_dns(api_url, retries=0, backoff=2):
    """
    Check DNS resolution for the host in api_url.

    Returns True if resolved, False if not.
    retries: number of additional resolution attempts (0 = no retry)
    backoff: base seconds between retries (backoff multiplier applied)
    """

    if not api_url:
        config.script.logger.error("test")
        return False

    parsed = urlparse(api_url)
    host = parsed.hostname
    if not host:
        config.script.logger.error(f"Unable to extract hostname from URL: {api_url}")
        return False

    attempt = 0
    while True:
        try:
            # getaddrinfo is recommended: supports IPv4/IPv6 and is portable
            socket.getaddrinfo(
                host,
                parsed.port or None,
                family=socket.AF_UNSPEC,
                type=socket.SOCK_STREAM,
            )
            return True
        except socket.gaierror as e:
            attempt += 1
            if attempt > retries:
                config.script.logger.error(
                    f"DNS lookup failed for host '{host}' (from URL: {api_url}).\n"
                    f"socket.gaierror: {e}\n"
                    "Check DNS, host name, or network connectivity."
                )
                return False
            else:
                wait = backoff * (2 ** (attempt - 1))
                config.script.logger.warning(
                    f"DNS lookup failed for '{host}', retry {attempt}/{retries} after {wait}s..."
                )
                time.sleep(wait)
        except Exception as e:
            # catch unexpected errors (permission, etc.)
            config.script.logger.error(
                f"Unexpected error resolving host '{host}': {e}", file=sys.stderr
            )
            return False


def int_in_range(min_val, max_val):
    def checker(value):
        ivalue = int(value)
        if ivalue < min_val or ivalue > max_val:
            raise argparse.ArgumentTypeError(
                f"{value} not in range {min_val}â€“{max_val}"
            )
        return ivalue

    return checker
